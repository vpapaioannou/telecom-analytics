# Peak Detection

This is the last step of the [Peak Detection](../../../../docs/PeakDetection.md) calculation
and it requires input generated by both the [Data Filter] (../dataFilter/README.md) and the 
[Distribution Computation] (../distributionComputation/README.md) steps.

For each region and each time-slot, the corresponding density is compared against its expected value: if the difference is significant, an event of form (region, weight, time slot) is produced, representing its spatiotemporal slot and a discretized measure (weight) of how strong was the deviation.
In particular, events are detected on the base of three parameters:
* a granularity of deviations, expressed as a percentage relative to the expected density; 
* a minimum relative deviation, also expressed as a percentage, used to select significant deviations; 
* an absolute minimum deviation, expressed as an integer number, used to discard extreme cases with very low densities. 

The weights used in defining events will be multiples of the granularity, and an event for a region and a time slot will be built only if the deviation of its density w.r.t. the corresponding expected density is larger than the absolute minimum deviation and in percentage is larger than the minimum relative deviation.

## Implementation Details

As an spark application, this operator can be executed by being submitted in an running spark installation.
For simplifying the execution [submit.sh] (../../../../submit.sh) can be used.

**Usage**:

./submit.shÂ ta.PeakDetection \<master\> \<cpBaseFile\> \<testDataFile\> \<binSize\>

**Input parameters**:
- the spark master URI
- the cpBase dataset URI (HDFS or local)
- the testData table URI (HDFS or local)
- the ouput path
- the bin size: the size of the events ratio bins (i.e. 10%)

**Output**:
Upon successful execution the \<output\>/events & \<output\>/eventsFilter datasets will be created.

e.g.:

./submit.sh ta.PeakDetection spark://localhost:7077 /output/cpBase /output/testData /output 0.1

## SQL formalization:

    //The peak detection, also called events. Here the variation is computed in percentage of the standard amount of people calling from a tower in a certain hour.
    create table events as
    select  a.rid, a.hour, a.doy, a.dow, 
        ((CAST(a.num AS numeric)/am.num)/
        (CAST(b.num As numeric)/bm.num))
        -1.0 as ratio, a.num as anum, b.num as bnum
    from 
        cp_analyze a, 
        cp_base b, 
        (select doy, dow, sum(num) as num from test_data group by doy, dow) am,
        (select dow, sum(num) as num from cp_base group by dow) bm
    where 
    a.rid=b.rid and 
    a.hour=b.hour and 
    a.dow = b.dow and
    b.dow = bm.dow and
    a.doy = am.doy;

**//After the detection of the peaks they are categorized into bins (in this example 10%) and they are filtered by two constrains: the first one in percentage (minimum 20%) and the second one using an absolute value (minimum 50 calls). An additional constraint can be used to select only the positive variations (ratio>0). The size of bins and the constraints are parameters which may vary the kind of peaks we are interested on.**

    CREATE TABLE events_filter AS
    SELECT rid, hour, doy, dow, floor(abs(ratio/0.1))*0.1*sign(ratio) as ratio 
    FROM events
    WHERE abs(ratio) >= 0.2 AND
    abs(anum-bnum) >= 50 and 
    ratio>0
